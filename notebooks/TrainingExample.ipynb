{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example training notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add work directory\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# you should add root directory\n",
    "sys.path.append(os.path.dirname(\"../\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Figaro dataset using get_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataloader\n",
    "\n",
    "from data import get_loader\n",
    "\n",
    "# you have to predefine transforms to load dataset\n",
    "# this transforms images and masks while loading\n",
    "# example transforms\n",
    "\n",
    "from utils import joint_transforms as jnt_trnsf\n",
    "import torchvision.transforms as std_trnsf\n",
    "\n",
    "\n",
    "# transforms that are applied to both images and masks\n",
    "# includes geometrical changes like flip\n",
    "# implemented in ./utils/joint_transforms.py\n",
    "joint_transforms = jnt_trnsf.Compose([\n",
    "    jnt_trnsf.Resize(256),\n",
    "    jnt_trnsf.RandomRotate(5),\n",
    "    jnt_trnsf.CenterCrop(224),\n",
    "    jnt_trnsf.RandomHorizontallyFlip()\n",
    "])\n",
    "\n",
    "\n",
    "# transforms that are applied to only images\n",
    "# this includes color jittering, normalizing, blurring, etc\n",
    "# use torchvision.transforms, or implement additional transforms in 'utils'\n",
    "train_image_transforms = std_trnsf.Compose([\n",
    "    std_trnsf.ColorJitter(0.05, 0.05, 0.05, 0.05),\n",
    "    std_trnsf.ToTensor(),\n",
    "    std_trnsf.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "test_image_transforms = std_trnsf.Compose([\n",
    "    std_trnsf.ToTensor(),\n",
    "    std_trnsf.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# transforms that are applied to only masks\n",
    "mask_transforms = std_trnsf.Compose([\n",
    "    std_trnsf.ToTensor()\n",
    "    ])\n",
    "\n",
    "# predifine other needed arguments\n",
    "batch_size = 4\n",
    "num_workers = 1\n",
    "data_dir = '../data/Figaro1k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(dataset='figaro',\n",
    "                          data_dir=data_dir,\n",
    "                          train=True,\n",
    "                          joint_transforms=joint_transforms,\n",
    "                          image_transforms=train_image_transforms,\n",
    "                          mask_transforms=mask_transforms,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "test_loader = get_loader(dataset='figaro',\n",
    "                         data_dir=data_dir,\n",
    "                         train=False,\n",
    "                         joint_transforms=joint_transforms,\n",
    "                         image_transforms=test_image_transforms,\n",
    "                         mask_transforms=mask_transforms,\n",
    "                         batch_size=1,\n",
    "                         shuffle=False,\n",
    "                         num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, torch.Size([4, 3, 224, 224]), torch.Size([4, 1, 224, 224]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two ways of iterating dataloader\n",
    "\n",
    "# 1. using for loop\n",
    "\n",
    "for step, (data, target) in enumerate(train_loader):\n",
    "    break\n",
    "step, data.size(), target.size() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 224, 224]), torch.Size([4, 1, 224, 224]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# 2. using iterator\n",
    "batch_iterator = iter(train_loader)\n",
    "\n",
    "for _ in range(10):\n",
    "    data, target = batch_iterator.next()\n",
    "data.size(), target.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import get_network\n",
    "\n",
    "# you can add your own model in get_network fuction in ./networks/__init__.py \n",
    "model = get_network(name='SegNet', num_class = 1)\n",
    "\n",
    "# or just import directly\n",
    "from networks.segnet import SegNet\n",
    "model = SegNet(num_class = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Optimizer & Scheduler & loss & device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.optim\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr = 0.001, \n",
    "                             betas=(0.5, 0.999), # beta1 acts like 'momentum' in SGD\n",
    "                            )\n",
    "\n",
    "# torch.\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# torch.nn\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# flag to use gpu or not\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pytorch Ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignite moduels\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss\n",
    "\n",
    "# custom modules\n",
    "from utils.metrics import Accuracy, MeanIU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer and evaluator\n",
    "trainer = create_supervised_trainer(model, optimizer, loss, device=device)\n",
    "evaluator = create_supervised_evaluator(model,\n",
    "                                        metrics={\n",
    "                                            'pix-acc': Accuracy(),\n",
    "                                            'mean-iu': MeanIU(0.5),\n",
    "                                            'loss': Loss(loss)\n",
    "                                            },\n",
    "                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving training state if you want\n",
    "from utils import update_state\n",
    "state = update_state(model.state_dict(), 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(trainer):\n",
    "    num_iter = (trainer.state.iteration - 1) % len(train_loader) + 1\n",
    "    if num_iter % 20 == 0:\n",
    "        print(\"Epoch[{}] Iter[{:03d}] Loss: {:.2f}\".format(\n",
    "            trainer.state.epoch, num_iter, trainer.state.output))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    # evaluate training set\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Training Results - Epoch: {}  Pix-acc: {:.3f} MeanIU: {:.3f} Avg-loss: {:.3f}\".format(\n",
    "        trainer.state.epoch, metrics['pix-acc'], metrics['mean-iu'], metrics['loss']))\n",
    "\n",
    "    # update state\n",
    "    update_state(model.state_dict(), metrics['loss'], state['val_loss'], state['val_pix_acc'], state['val_miu'])\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    # evaluate test(validation) set\n",
    "    evaluator.run(test_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Pix-acc: {:.2f} MeanIU: {:.3f} Avg-loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['pix-acc'], metrics['mean-iu'], metrics['loss']))\n",
    "\n",
    "    # update scheduler\n",
    "    scheduler.step(metrics['loss'])\n",
    "\n",
    "    # update and save state\n",
    "    update_state(model.state_dict(), state['train_loss'], metrics['loss'], metrics['pix-acc'], metrics['mean-iu'])\n",
    "    save_ckpt_file(\n",
    "        ckpt_path.format(network=networks, epoch=trainer.state.epoch),\n",
    "        state)\n",
    "\n",
    "trainer.run(train_loader, max_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do this in one-queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# run this in root\n",
    "\n",
    "python3 main.py \\\n",
    "  --networks segnet \\\n",
    "  --scheduler ReduceLROnPlateau \\\n",
    "  --batch_size 4 \\\n",
    "  --epochs 100 \\\n",
    "  --lr 1e-3 \\\n",
    "  --num_workers 4 \\\n",
    "  --optimizer adam \\\n",
    "  --momentum 0.5\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
